:source-highlighter: rouge
= Module AI


== Introduction

Members :

- Titouan MENDIHARAT
- Nans WEBERT


Our project is simple to understand : we want to accelerate administrative processes (like ID's renewal, school registration, etc..).

To do this, we came up with a concept : a browser extension which can automatically fill forms. But there is a security problem with an extension, the browser storage isn't very safe.

To secure the installation, we decided to add an other part in the project : a desktop application where the user can fill in his informations.

With the application and the browser extension, the user will :

- fill in his informations in the desktop app
- the desktop app will save data in an encrypted file on the computer
- when a user goes on a webpage where there is a form, it detects it
- the extension calls the desktop app thanks to his API (the desktop app will create a local server with an API)
- the desktop app decrypts the file and sends back correct informations
- the extension fills the form with the data

The module IA is here to do the step **detection of the form**. To achieve the detection, Titouan though about an AI.

== Tools and methods


**PyTorch**

As none of us knew about AI, we decided to take the course of PyTorch.

The first course was about building an AI to do image detection.
This is what the program does :

- it loads a dataset from the fashionMIST dataset
- it trains an AI with the dataset
- the program creates a model (and saves it to a file).
- the model is used with an image

**TensorFlow**

After that Pytorch tutorial (which was long), we also tried to use tensorflow (with the Quick start tutorial).

**PyTorch Text**

The result was concluant. But not perfect because tutorials where on image data, and we wanted to work on text data. So we looked for a PyTorch tutorial for text since it works a bit differently (it was text classification).

**Dataset**

Then we figured out that we needed to find or create a dataset for our project.
https://towardsdatascience.com/how-to-use-datasets-and-dataloader-in-pytorch-for-custom-text-data-270eed7f7c00[How to create a dataset]

Unfortunately, there was no dataset for HTML forms. So we decided to create it.

The process of dataset creation :

- create a class for the dataset
- get data and label (result) for the class
- initiate the class with the data
- define a `collate` function for a dataloader
- create a `DataLoader` with the initialized class
- use the dataloader to train

We saw that in the PyTorch text, we used a tokenizer to split data and then transform the data in vector. As we work with HTML, we need our own tokenizer (see part **`Code`**)

== Results and discussion

After the course we had a working AI !

The main problem is the dataset we need to create : we need to create a new dataset which is complicated, since we have to find as much online forms as possible, but we started to do that. To create the dataset, we are going to scroll the web in search of as many forms as possible.

Our Tech Stack in the project is full JavaScript, so a problem may appear during the integration of the module in the app.

Fortunately, we searched on the web and found different programs to transfer a model to a JavaScript programs :

- https://github.com/torch-js/torch-js[https://github.com/torch-js/torch-js] for PyTorch
- https://github.com/elliotwaite/pytorch-to-javascript-with-onnx-js[https://github.com/elliotwaite/pytorch-to-javascript-with-onnx-js] for PyTorch with a transformation in an ONNX model and using ONNX.js
- https://www.tensorflow.org/js/tutorials?hl=fr[https://www.tensorflow.org/js/tutorials] tensorflow in javascript
- https://ml5js.org/[https://ml5js.org/] a wrapper for tensorflow.js

We though about different designs :

- The extension sends a part of a page to the Desktop app and the detection is made in the Desktop app but running python program (like in a `shell`).
- The extension sends a part of a page to the Desktop app and the detection is made in the Desktop app with an AI model converted in JS.
- The extension analyzes the page (without sending it to the Desktop app) and the detection is done through an AI model converted in JS.

We though that the last one probably is the best option.

== Code and Vocabulary

All the code is in our **PACT repository in GitLab**. Here is some useful code that we used.

---

- **batch size** : The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.

- **Epoch** : The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.

- **Tensor** : a multi-dimensional matrix containing elements of a single data type.

- **DataLoader** : an iterable over a dataset with various useful option

---

Save a model :
```py
torch.save(model.state_dict(), "./model")
```

---

Load a model :
```py
# create an model and load the dict and eval it to work
model = ClassOfTheModel()
model.load_state_dict(torch.load("./model"))
model.eval()
```

---

Load a dataset :
```py
dataloader = DataLoader(train_iter, batch_size=8,
                        shuffle=True, collate_fn=collate_batch)
```

- The `shuffle` options will reshuffle the data at each epoch, this prevents the model from learning the order of training data
- The `collate_fn` options is used to create separate data processing functions and will apply the processing within that function to the data before it is output.

---

When we create a model, we use a tokenizer. In our case, we need a special tokenizer because we want it to tokenize HTML

Here is what we produced :
```py
def tokenizer(text):
    temp = text.split("\n")
    final = []
    for oneLine in temp:
        elements = oneLine.split(">")
        for oneWord in elements:
            if oneWord != "":
                final.append((oneWord + ">").strip())
    return final
```

---